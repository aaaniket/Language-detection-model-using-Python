{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff3e424b",
   "metadata": {},
   "source": [
    "# Language Detection with Machine Learning\n",
    "\n",
    "Language detection is a crucial task in natural language processing (NLP) that involves identifying the language of a given piece of text. This capability is particularly important in today’s globalized environment where digital platforms often handle multilingual content. Machine learning, especially with the availability of extensive language data, has become a powerful tool to automatically and accurately detect languages. This process not only supports translation services like Google Translate but also enhances content moderation, targeted advertising, and customer support across different regions.\n",
    "\n",
    "**Workflow for Building a Language Detection Model**\n",
    "\n",
    "The workflow for developing a machine learning model for language detection typically involves the following steps:\n",
    "\n",
    "1. **Data Collection**: Gather a dataset containing text samples labeled with their corresponding languages. This dataset should ideally be balanced across the languages of interest.\n",
    "\n",
    "2. **Data Preprocessing**: Clean and prepare the data for modeling. This includes handling missing values, removing noise, and converting text data into a suitable format for machine learning models using techniques like tokenization and vectorization.\n",
    "\n",
    "3. **Feature Extraction**: Use techniques like Count Vectorization to convert text into numerical features that machine learning models can process.\n",
    "\n",
    "4. **Model Selection**: Choose a suitable machine learning algorithm for language detection. Multinomial Naive Bayes is a popular choice due to its effectiveness in dealing with discrete features and its efficiency with large datasets.\n",
    "\n",
    "5. **Training**: Train the chosen model on the prepared dataset. This involves feeding the model with training data so it can learn to associate the features with the corresponding language labels.\n",
    "\n",
    "6. **Evaluation**: Test the model’s performance using a separate set of data (test set). This helps in assessing the accuracy and generalizability of the model.\n",
    "\n",
    "7. **Deployment and Prediction**: Once trained and validated, the model can be deployed to make predictions in real-time. This could involve integrating the model into applications that require language detection.\n",
    "\n",
    "By following these steps, you can build a robust machine learning-based system for detecting languages in texts, enabling applications to better handle and analyze multilingual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82edd587",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text  language\n",
      "0  klement gottwaldi surnukeha palsameeriti ning ...  Estonian\n",
      "1  sebes joseph pereira thomas  på eng the jesuit...   Swedish\n",
      "2  ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เ...      Thai\n",
      "3  விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திர...     Tamil\n",
      "4  de spons behoort tot het geslacht haliclona en...     Dutch\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Load dataset from the provided URL\n",
    "data = pd.read_csv(\"C:/Users/anike/OneDrive/Desktop/Projects/Machine Learning/Language Detection/dataset.csv\")\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0615723e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text        0\n",
      "language    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking for any null values in the dataset\n",
    "print(data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "204650ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estonian      1000\n",
      "Swedish       1000\n",
      "English       1000\n",
      "Russian       1000\n",
      "Romanian      1000\n",
      "Persian       1000\n",
      "Pushto        1000\n",
      "Spanish       1000\n",
      "Hindi         1000\n",
      "Korean        1000\n",
      "Chinese       1000\n",
      "French        1000\n",
      "Portugese     1000\n",
      "Indonesian    1000\n",
      "Urdu          1000\n",
      "Latin         1000\n",
      "Turkish       1000\n",
      "Japanese      1000\n",
      "Dutch         1000\n",
      "Tamil         1000\n",
      "Thai          1000\n",
      "Arabic        1000\n",
      "Name: language, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display the count of each language in the dataset\n",
    "print(data[\"language\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39933f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and labels from the dataset\n",
    "x = data[\"Text\"]\n",
    "y = data[\"language\"]\n",
    "\n",
    "# Create a CountVectorizer instance to convert text data into vectors\n",
    "cv = CountVectorizer()\n",
    "\n",
    "# Transform the text data into feature vectors\n",
    "X = cv.fit_transform(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c096caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67306d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on test set: 0.953168044077135\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the Multinomial Naive Bayes classifier\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "print(\"Model accuracy on test set:\", model.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41b2a866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a Text: 某物\n",
      "The language of the text is: Chinese\n"
     ]
    }
   ],
   "source": [
    "# Function to predict the language of a given text\n",
    "def predict_language(text):\n",
    "    transformed_text = cv.transform([text]).toarray()\n",
    "    prediction = model.predict(transformed_text)\n",
    "    return prediction[0]\n",
    "\n",
    "# Taking user input and predicting the language\n",
    "user_input = input(\"Enter a Text: \")\n",
    "predicted_language = predict_language(user_input)\n",
    "print(f\"The language of the text is: {predicted_language}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
